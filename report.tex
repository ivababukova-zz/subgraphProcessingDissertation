\pdfoutput=1

\documentclass{l4proj}

%
% put any packages here
%
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{subcaption}
\usepackage{float}
\usepackage{array,multirow}
\usepackage{url}
\usepackage{hyperref}
\usepackage[table]{xcolor}
\usepackage{array}
\usepackage{booktabs}
\definecolor{Gray}{gray}{0.85}
%definitions and theorems
%\theoremstyle{definition}
%\newtheorem{myDef}{Definition}[section]

\newcounter{example}[section]
\newenvironment{example}[1][]{\refstepcounter{example}\par\medskip
   \noindent \textit{Example~\theexample #1} \rmfamily}{\medskip}


%\newtheoremstyle{definition}% name
%  {}%         Space above, empty = `usual value'
%  {}%         Space below
%  {}% Body font
%  {}%         Indent amount (empty = no indent, \parindent = para indent)
%  {\bfseries}% Thm head font
%  {.}%        Punctuation after thm head
%  {\newline}% Space after thm head: \newline = linebreak
%  {}%         Thm head spec
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}{Definition}

\begin{document}
\title{Investigations of Subgraph Query Processing}
\author{Iva Stefanova Babukova}
\date{March 20, 2016}
\maketitle

\begin{abstract}


\end{abstract}

\educationalconsent
%
%NOTE: if you include the educationalconsent (above) and your project is graded an A then
%      it may be entered in the CS Hall of Fame
%
\tableofcontents
%==============================================================================
\chapter{Introduction}
\pagenumbering{arabic}
	\section{Problem Statement}
    \section{Aims and Motivations}
    
    Many substructure-searching problems call for repeatedly examining a large number of molecules (typically stored in a database), comparing each with a pattern. In such situations, it pays to spend some time "up front," storing the answers to specific questions for each structure in the database. Subsequent searches of the database use these pre-computed answers to vastly improve search time; the up-front computation time is paid back quickly as repeated searches are performed.


    
        \begin{itemize}
            \item graphs are widely used nowadays to represent data
            \item the graph containment problem is widely addressed in many areas of science: genetics, chemistry, XML documents, images, fraud detection and prevention (there was an article in nature about this)
        \end{itemize}
        
        In the core of many graph-related applications, lies a common and critical problem: \textit{how to efficiently process graph queries and retrieve related graphs}. In some cases, the success of an application directly relies on the efficiency of the query processing system.  
        
        Applications:
        \begin{itemize}
        \item genome sequencing: find mutations responsible for rare diseases -- nature vol 527 no 7576
        \item treating diseases like cancer: screen a patient's tumor for a set of biomarkers to choose the best treatment to fight the particular cancer -- nature vol 527 no 7578
        \end{itemize}
        
\section{Graph Theory, terminology and definitions}
        In this section, we introduce preliminary concepts and outline the main concepts and problems addressed in the document. In definition \ref{def:graphFormat} we explain the format of all graphs used in the document.
    \subsection{Graph Theory}
    \subsection{Terminology}
    \label{naming}
    - The set of target graphs: T
    - Each graph in t: $t^{}_i$, for i from 1 to the number of graphs in T
    - The set of pattern graphs: P
    - Each pattern graph in P: $p^{}_j$, for i from 1 to the number of graphs in P
    - The candidate set of graphs: C. It is important to not that C is contained in T
    - There is a trade off between the size of C and the time it takes to be computed.
        
	\subsection{Definitions}
    \label{subsec:definitions}
        \begin{definition}[Graph]
        
        \end{definition}
        
        \begin{definition}[Sub-graph]
        \label{def:subgraph}
        
        \end{definition}
        
        \begin{definition}[Induced Sub-graph]
        \label{def:induced-subgraph}
        
        \end{definition}
    
        \begin{definition}[Graph Format]
        \label{def:graphFormat}
        A graph G = (V, E, L, $\lambda$) is defined as an undirected labeled graph where V is the set of vertices, E is the set of edges(unordered pair of vertices), L is the set of labels, and $\lambda$ is a labeling function, $\lambda$ : V $\cup$ E $\rightarrow$ L, that assigns labels to vertices and edges.
        \end{definition}
        
        \begin{definition}[Graph Isomorphism]
        
        \end{definition}
        
        \begin{definition}[Induced Graph Isomorphism]
        \label{def:inducedGraphIsomorphism}
        
        \end{definition}

        \begin{definition}[Subgraph Isomorphism]
        \label{def:subgraphIsomorphism}
        Given a graph database T of target graphs $t^{}_0$, $t^{}_1$, $t^{}_2$ \ldots $t^{}_i$, where \textit{i} is the number of target graphs in T, and a pattern graph P, find all targets in T that have P as a subgraph.
        \end{definition}
        
        \begin{definition}[Induced Subgraph Isomorphism]
        \label{def:inducedSubgraphIsomorphism}
        
        \end{definition}
        
        \begin{definition}[Graph Density]
        
        \end{definition}
        
        \begin{definition}[Subgraph]
        \label{def:subgraph}
        A graph whose vertices and edges are a subset of another graph.
        \end{definition}
        
        \begin{definition}[Graph Query Processing]
        \label{def:graphQueryProcessing}
        Given a graph database D = $\{$ $g^{}_0$, $g^{}_1$, $g^{}_2$ \ldots $g^{}_n$ $\}$ and a pattern graph p, it returns the query answer set $D^{}_p$ = $\{$ $g^{}_i$$\vert$p $\subseteq$ $g^{}_i$, $g^{}_i$ $\in$ D $\}$
        
        \end{definition}
        
        \begin{definition}[In-memory computing]
        The storage of information in the main random access memory (RAM) of dedicated servers rather than in relational databases operating on comparatively slow disk drives.In-memory computing gives ability to cache countless amounts of data constantly. This ensures extremely fast response times for searches.
        \end{definition}
        
        \begin{definition} [Graph Index]
		
		\end{definition}

	\section{Subgraph Isomorphism}
    \section{Report Organization}

\chapter{Review of existing work}
\section{The nature of the problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Datasets %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Datasets}
\label{sec:datasets}

    In this work we consider undirected graphs. We assume that, in each graph, each vertex has a unique identifier and in the graph database each graph has a unique identifier. 

This section gives more information about the datasets that were used to check the correctness and performance of the algorithm implementations. All graphs in these datasets are undirected.\par
\textbf{AIDS} is the standard database of the Antiviral Screen dataset of the National Cancer Insitute \cite{datasets}. The database has 40 000 molecules, represented as graphs. 

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.4}% Spread rows out...
\begin{tabular}{ >{\bfseries}m{1.5in} >{\centering}m{0.5in} >{\centering}m{0.5in} >{\centering}m{0.5in} >{\centering\arraybackslash}m{0.5in}  } 
\toprule
   						   & aids   & pcms  & pdbs  & ppigo \\
\midrule
 \# graphs 				   & 40 000 & 200	& 600   & 50 \\
 \# disconnected graphs$*$ & 3 157  &		&		&  \\ 
 \# distinct node labels   & 62	    &		& 		&  \\ 
 \# distinct edge labels   & 0 		& 0		& 0		& 0 \\ 
 avg \# edges			   & 46.95  & 		&		&  \\ 
 median \# edges		   & 	    &		&		&  \\ 
 avg \# nodes			   & 45		&		&		&  \\ 
 avg degree				   & 2.09	&		&		&  \\ 
 median \# nodes	       &		&		&		&  \\ 
 avg \# node labels		   & 4.4	&		&		&  \\ 
 median \# node labels     &		&		&		&  \\
 \bottomrule
\end{tabular}
\caption{Statistics about the datasets}
\label{table:datasets}
\end{table}    


\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.3}% Spread rows out...
\begin{tabular}{ |>{\bfseries}m{0.5in} |>{\centering}m{0.8in}| >{\centering}m{0.8in}| >{\centering}m{0.8in}| >{\centering}m{0.8in}| >{\centering\arraybackslash}m{0.8in}|} 
\hline
 dataset & number of graphs & unique vertex labels & average node degree  & min node degree & max node degree\\
\hline
AIDS & 40 000 & 62 & 2.09 & ne znam & ne znam \\
\hline
PCMS & 200 & 21 & 23.01 & ne znam & ne znam \\
\hline
PDBS & 600 & 10 & 2.06 & ne znam & ne znam \\
\hline
PPIGO & 20 & 46 & 10.87 & ne znam & ne znam\\
\hline
\end{tabular}
\caption{Characteristics of the datasets}
\label{table:datasets}
\end{table}    


\small{$*$ A graph G is said to be disconnected if there exist two nodes in G such that no path in G has those nodes as endpoints.}

    The input we are working with is a file with the following format:\newline
    
    - put a table with the datasets and more information about them \\ 
    - average, median, etc. \\
    - say we work only with undirected graphs \\
    - say whether we consider induced/ non-induced subgraph isomorphism \\

\subsection{Subgraph Isomorphism Answers}
Each query in each query set matches at least one graph in the target set. Some queries match more than one graph. Below we give some statistics on number of target graphs matched.
\begin{table}[H]
\caption{Solvable instances per dataset}
\label{table:dataSAT}
\centering
\renewcommand{\arraystretch}{1.4}
\begin{tabular}{|>{\centering}m{1.5in}|c|c|c|c|c|}\hline

satisfiable instances & AIDS   & PCM  & PDBS  & PPIGO \\ 
 \hline
 average \%           & 8.590  & 26.5 & 69.42 & 24.4  \\
 median \%            & 0.673  & 19   & 83.3  & 26    \\
 minimum \%           & 0.0075 & 2    & 22.67 & 14    \\
 maximum \%           & 29.89  & 72   & 96.7  & 34    \\
 \hline
\end{tabular}
\end{table}


\section{Filtering-verification paradigm}
- smaller $C$, less time spent on subgraph isomorphism check, but more tie spent on indexing process

	\section{Motivation for usage}
    \section{What makes an index "good"}
	\section{Common techniques}
    	\subsection{Graph-mining}
    	\subsection{Non-graph-mining}
        \label{subsec:non-data-mining}
    \section{Methods with respect to choice of indexing unit}
        \subsection{Path-based indexing approach}
        Follows the general idea: enumerate all the existing paths in a database up to \textit{maxLen} length and index them, where a path is a vertex-edgeProperty-vetex sequence. *example*
        In order to create an index of a graph \textit{g}, this approach breaks \textit{g} into paths and in this way, the structural information of \textit{g} could be lost. This leads to more false-positive answers returned after the   
        Advantages:
        \begin{enumerate}
            \item Paths are easier to manipulate than trees and graphs.
            \item The index space is predefined: all the paths up to             \textit{maxLen} length are selected.
        \end{enumerate}
        
        Disadvantages:
        \begin{enumerate}
            \item Path is too simple: structural information is lost
            \item There are too many paths: the set of paths in a graph database usually is huge.
        \end{enumerate}
        \subsection{Tree-based indexing approach}
        
\subsection{CT-Index}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%                               CT-Index                               %%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TODO: move this to a background information section
%%% TODO: give a definition of a path in a graph : A path in a graph is a sequence of distinct vertices, such that each successive pair of vertices are adjacent; we also allow a path from a vertex to itself, in which case the first and last vertices in the sequence are the same (and there is a cycle).
% TODO: prove that from paths we can safely discard graphs as not subgraph isomorphic if they don't have the same paths.

%
%
% NOTE 1 FROM PATRICK
% You need to be consistent. There is confusion between vertices and nodes. Please resolve this
% What I have done (and you might state) is that we assume nodes are in trees constructed from a pattern or target
% graph composed of vertices and that you do this to distinguish between the two
%
CT-Index \cite{ctindex} is divided into two main parts, filtering and verification, both described below. Also presented is a complexity analysis of the algorithms used by CT-Index and an empirical study of its performance (using an open-source Java implementation).
CT-Index supports data sets with edge and vertex labels and also wild card patterns. Although not explicitly stated in \cite{ctindex}, CT-Index addresses the non-induced subgraph isomorphism problem  ( definition \ref{def:subgraphIsomorphism}).

\subsubsection{Filtering}
During the filtering step, the features of all graphs in the target data set are extracted and saved to a file, i.e. the target index. The index is then used to filter out target graphs that cannot contain the pattern.  Features are specific subgraphs used to classify graphs, and are stored as hash-key fingerprints. Features may be paths, subtrees or cycles of bounded length. Since vertices and edges may contain labels, these features can be viewed as strings from a specified alphabet (where the alphabet is the labels). In \cite{ctindex} it is stated that the reason for using trees and cycles (as well as paths) is that ``trees capture additional structural information" and cycles ``represent the distinct characteristic of graphs ... often neglected when using only trees as features".

%
% NOTE 2 FROM PATRICK
% Note simple way to use maths
%
Although the time complexity of computing all features of a graph is not reported, it can be derived as follows. To extract a subtree of graph $G$ with $maxT$ number of edges, one starts with initially empty tree and repeatedly adds edges to extend the vertices that are in the current tree via the recursive function $ExtendTree$. We write $F$ for the set of every edge $(u,v)$ in $G$ and vertices $u$ and $v$ that belong to $G$, such that one vertex (say, $u$) is part of the current tree and the other (say, $v$) is not. If we have $n$ number of vertices in the current tree, each with degree $d$, then the size of $F$ is at most $n(d-1)$. $ExtendTree$ extends the current tree with a specified edge as parameter, generates $F$ and makes a recursive call for every edge in $F$, until the tree reaches size $maxT$.
%%% todo for the big O
In the start of the tree extraction when adding the first edge to the empty tree, the vertices on both ends of the edge are also added as part of the tree. Therefore, the size of $F$ initially is $2.(d-1)$. After every recursive call, one more vertex is added to the tree, which introduces $(d-1)$ new edges. That makes a total of $maxT+1$ vertices that will be added to the tree and $(maxT+1).(d-1)$ visited edges. Consequently, the complexity of extracting tree features is $\mathcal{O}(|E|.(maxT+1).(d-1))$. From this formula one can see that the number of edges in the graph has significant impact on the performance of the algorithm. When increasing the graph density, the algorithm will have slower performance, caused by the degree of each vertex and the total number of edges, which both will increase.

CT-Index computes a unique representation of each distinct feature, its \emph{canonical form}, and stores its string encoding in the index file. Thus, the equality of two features can be checked by testing the equality of their canonical forms. The canonical label of a tree feature is computed as follows: (1) find the root node $r$ of the tree, (2) impose a unique ordering of the children of each node. Step (1) is computed by repeatedly removing all leaf nodes of a tree until a single node or two adjacent nodes remain. In the first case, root $r$ is the last node left. In the second case the edge connecting the two remaining nodes are removed to obtain two trees, each with one of the remaining nodes as a root. 
Step (2) is based on the ordering of edge and vertex labels. For each node $p$ that is a parent of nodes $u$ and $v$, deciding whether $u$ is before $v$ depends first on the labels of the edges $(p,u)$ and $(p,v)$, then on the labels of $u$ and $v$ and finally on the subtrees of $u$ and $v$. A bottom-up approach is used (i.e. start with the nodes in the lowest level and move up towards the root) to compute this.

%%%% complexity of canonical label algorithm %%%%
Although not stated in \cite{ctindex} the complexity of their canonical labeling can be derived as follows. Step (1) is $\mathcal{O}(n)$, where $n$ is the number of nodes in the tree, as one needs to visit each node before removing it. The complexity of step (2) is as follows. We write $|p|$ for the number of interior nodes in the trees, which is equal to $n$ minus the number of leaf nodes. Step (2) visits a node, then visits its parent, and for every child of the parent node checks whether it should be first or second in the canonical label, using the vertex and edge labels conditions described above. This is repeated for every node in the tree up to the root. Therefore, the complexity of step (2) is $\mathcal{O}(|p|.|c|^{2})$, where $|c|$ denotes the number of children of a parent.

%%% 
In \cite{ctindex} it is claimed that step (2) is not linear time but is tolerable because ``... the trees occurring as features usually are small and vertex and edge labels are diverse and hence the order can be solved quickly". Therefore, we might assume that CT-Index is designed to support only specific types of data sets and that there exists data sets with less label diversity and with big trees as features that would result in poor performance. More specifically, as $maxT$ increases, or average degree increases, so too does the cost of step (2), and performance suffers (and we conduct experiments to test this hypothesis in section \ref{sec:ct-index-performance}).


\subsubsection{Fingerprints}
%%%% hash-key fingerprints %%%%
CT-Index uses a storage technique called \emph{hash-key fingerprint} to capture the features in the graph. A separate fingerprint is computed from the canonical labels for each graph in the database. A fingerprint is an array of bits and denotes whether a particular feature occurs in the graph or not. As there is no predefined set of possible features for each graph, reserving one bit for each feature in the feature set is considered infeasible\footnote{However, due to the restricted alphabet of labels it may be possible to enumerate all possible features thus avoiding some of the pitfalls of hashing, such as collisions and sensitivity to hash table size.}. A hash function maps extracted features to bit positions.
CT-Index is not the first indexing algorithm to employ fingerprints as a storage technique. The chemical information system called Thor and developed by Daylight \cite{fingerprints} is an example of an information processing system that uses bit arrays to store the features of the graphs.

%%%
Depending on the quality of the hash function, the size of the bitset and the size of the fingerprint, collisions may occur, i.e. different features may map to the same bitset position, introducing false-positives. The \cite{ctindex} paper briefly discussed some optimization techniques that could be used to minimize the influence of collisions, but it is unclear whether CT-Index employs them. 
It is stated that ``... the loss of information caused by the use of hash-key fingerprints seems to be justifiable by the compact nature and convenient processing of bit arrays as long as the amount of false positives does not increase significantly due to collisions".

Collisions can occur also if the size of the fingerprint is too small for the particular data, i.e. there is bigger number of features than the number of spaces in the array to store them. On the other hand, making the fingerprint size too big introduces additional overhead by requiring more memory storage space that is not used. The paper does not specify the hash function used or how to decide on the size of bitsets (feature hash tables). 

%%%% advantages %%%%
The main advantage of hashing the features and storing them in arrays is that this makes certain operations much cheaper. For example, checking whether a pattern fingerprint is included in a target fingerprint involves inexpensive bit operations. In particular, one only needs to compute a bitwise AND-operation with the two fingerprints to determine if features in the pattern exist within the target. If this test returns false then the target cannot be a candidate for that pattern. However, if it returns true then the target \emph{may} be a candidate and subgraph isomorphism must be verified.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\subsubsection{Verification}
The verification step checks all candidates computed in the filtering step via a subgraph isomorphism test. A backtracking algorithm \cite{backtracking-algorithms}, similar to VF2 \cite{vf2} with additional heuristics, is used.  This test is theoretically NP-Complete, and is avoided as far as possible via the filtering process. CT-Index is not alone in using (essentially) the VF2 algorithm.
For example it is used in GraphGrepSX \cite{graphgrepsx}, gCode \cite{gcode} and Tree+$\Delta$ \cite{tree+delta>=graph}. Most papers claim that VF2 is ``state of the art".  However, this is not the case (\cite{Solnon:2010,Larrosa:2002,Bonnici:2013,Zampelli:2010,CP2015}.
VF2 has been shown to perform erratically and poorly \cite{CP2015}. Therefore we might summarise CT-Index architecture as using a potentially expensive indexing and filtering stage in order to minimise the computational cost of using an outdated subgraph isomorphism problem (SIP) algorithm.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Performance}
\label{sec:ct-index-performance}
%%%% foteini's paper %%%%
%%%% TODO rewrite that part %%%$
This section describes the performance 
We searched for more information in alternative sources. In \cite{foteini} the authors compare several well-established indexing techniques, including CT-Index and try to draw conclusions on their performance depending on a set of key-factor parameters. The authors use the four datasets described in section \ref{sec:datasets} as well as a synthetically generated database of targets and queries to conduct their experiments. These are some of the conclusions made after the experiments:
\begin{itemize}
%\item Datasets with increased number of distinct labels are easier and faster to index and compute subgraph isomorphism answers.\newline
%The reason for this result is straightforward, as the more distinct labels a graph has, the easier it is to discard nodes as possible matches to a pattern node, taking only the labels of nodes and edges into account.
\item The size of the query affects the performance of the indexing method\newline
This conclusion is also very easy to obtain. As the size of the pattern becomes larger, there are more nodes that have to be matched to a target node. Suppose that we have a pattern graph $p$ with $|p|$ number of nodes and a target graph $t$ with $|t|$ number of nodes that is a candidate for subgraph isomorphism. Assume that all techniques to discard $t$ before the search have failed, i.e. $|t|$ $\geq$ to $|p|$, etc. Then, for each node in $p$, the ct-index algorithm tries to map to a node in $t$ and continues until either it either fails or succeeds. In the first case, the algorithm backtracks and tries to map an alternative node from $t$ and in the second case, the algorithm terminates, as a valid map of all pattern nodes to some of the target nodes is found. One can easily notice that the bigger the size of $|p|$, the more checks the subgraph isomorphism algorithm will do. The same conclusion could be reached for $|t|$. When there are more nodes in $t$, more different ways exist for matching a node in $p$ to a node in $t$.
\item CT-Index has relatively small index size, compared to other indexing techniques.\newline
Again, this result could be obtained even without running any experiments. As the CT-Index uses bitset arrays to store the features, it straightforward to reach to the conclusion that CT-Index always has smaller index size, compared to other techniques that do not compress the features, but directly store them in the index file.\par
\end{itemize}
%%%
The results from \cite{foteini} have a major limitation: for each indexing methods, the authors use the "default" input parameter values, given by the original authors of each of the indexing methods. They never experiment with alternative values. It is not clear why the corresponding input values are fair and the best ones to use and why the authors do not consider the possibility of obtaining completely different results if they changed the input parameters values. Also, the authors never say whether they have checked how they verified that the indexing methods compared in the paper give correct results.\par
%%%% our evaluation %%%%
We conducted a separate evaluation using the implementation and the datasets descried in section \ref{sec:datasets}. Table \ref{table:runningTime} shows the running time of CT-Index: time to build the index, time to compute answers out of the set of candidates and the total running time depending on the values of the parameters specified for the AIDS dataset, namely the size of the fingerprint, the maximum bound for path, subtree and cycle size; and the number of candidates for after indexing and filtering for the corresponding query number. Table \ref{table:answers} shows the actual number of targets that contain the particular query as subgraph. This can be used to check the ratio of false-positives against real results for each query for each of the different input parameter values. We write -1 as the value of maximum path, cycle or subtree length whenever we do not want to use the corresponding structure as feature. We recorded the running time of both indexing and querying, as well as the number of candidates, because in real applications, the index is computed once and then reused multiple times, until the target dataset is changed. This means that for applications that require frequent changes to the database it is desirable to compute the index as fast as possible, whereas for datasets that are rarely changed, the time to compute the index is not that important and one may focus on increasing the quality of the index (i.e. it leads to smaller number of candidates).\par
To verify the correctness of the results obtained by CT-Index and later on be able to use the implementation as a benchmark, we did the following activities. As we did not have set of answers for each query, we first computed the answers for each query, varying the input parameters values. We verified that all results are the same by executing a script that checks whether every set of answers a query is the same as every set of answers obtained for the same query, but with different parameter values. Finally, we used a subgraph isomorphism solver program that does not employ indexing to compute the answers for each query and we compared these answers with the CT-Index answers to conclude that they are the same and CT-Index is correct at least for the corresponding input parameter values.\par
%%% 
%%%% big table with ct-index running times and results on the AIDS dataset %%
\newcommand\TstrutT{\rule{0pt}{2.6ex}}         % = `top' strut
\newcommand\Bstrut{\rule[-1ex]{0pt}{0pt}} 
\begin{table}[H]
\caption{CT-Index: Running time and results}
\label{table:runningTime}
\begin{center}
\begin{tabular}{ |c|p{25mm}|c|c|c|p{18mm}|}\hline
 & fingerprint size \newline max path len\newline max subtree len \newline max cycle len & index build T[sec]& query T[sec]& total T [sec] & \textbf{query\#} \#candidates\TstrutT\Bstrut\\
 \hline
1& 4096 -1 \,5 \,5  & 82.376 & 5.896 & 88.272 & \textbf{0} 11 160 \newline \textbf{1} 13 577 \newline \textbf{2} 975 \newline \textbf{3} 2 950 \newline \textbf{4} 2 575 \newline \textbf{5} 6 \TstrutT\Bstrut\\ 
 \hline
2 & 4096 \,5 \,5 \,\,5 & 108.465  & 5.948 & 114.413 & \textbf{0} 11 168 \newline \textbf{1} 13 589 \newline \textbf{2} 1058 \newline \textbf{3} 2 949 \newline \textbf{4} 2 576 \newline \textbf{5} 6 \TstrutT\Bstrut \\ 
 \hline
3 & 4096 \,5 -1 -1 & 37.621  & 7.929 & 45.550 & \textbf{0} 31 083 \newline \textbf{1} 36 458 \newline \textbf{2} 4 285 \newline \textbf{3} 7 261 \newline \textbf{4} 13 316 \newline \textbf{5} 252 \TstrutT\Bstrut \\ 
 \hline 
4 & 4096 \,5 \,\,1 \,\,1 & 41.482  & 7.96 & 49.442 & \textbf{0} 31 083 \newline \textbf{1} 36 458 \newline \textbf{2} 4 285 \newline \textbf{3} 7 261 \newline \textbf{4} 13 316 \newline \textbf{5} 252 \TstrutT\Bstrut\\ 
 \hline
5 & 2048 \,5 \,\,1 \,\,1 & 41.269  & 13.295 & 54.564 & \textbf{0} 31 085 \newline \textbf{1} 36 458 \newline \textbf{2} 4 293 \newline \textbf{3} 8 539 \newline \textbf{4} 13 319 \newline \textbf{5} 252 \TstrutT\Bstrut\\ 
 \hline
6 &  2048 \,-1 \,\,5 \,\,5 & 87.959  & 8.22 & 96.179 & \textbf{0} 11 540 \newline \textbf{1} 13 582 \newline \textbf{2} 987 \newline \textbf{3} 2 983 \newline \textbf{4} 2 660 \newline \textbf{5} 9 \TstrutT\Bstrut\\ 
 \hline
\end{tabular}
\end{center}
\end{table}
%%%
%%%% Analysis of the big table %%%%
Looking at rows 1 and 2, we can conclude that extracting paths as features as well as subtrees and cycles leads to significantly slower index built time and slightly worse filtering power. Comparing row 1 and row 3, one can see that extracting only paths takes significantly lower amount of time, compared to using only trees as features. However, it leads to worse filtering power. The results from rows 1, 2 and 3 support the claim that trees are much more descriptive features than paths. Also, they show that using paths, subtrees and cycles all together as features leads to slower running time.\par
%%%
As it can be seen that the rows with the smallest number of candidates are the ones that store trees in the index file (rows 1, 2 and 6), these are also the instances with the slowest index built time. The reason could be that trees are more complex than paths and require more time to be extracted and transformed to unique string representations. As explained in the previous section, the authors use algorithm that computes the canonical form the the features of high complexity. Maybe if the authors used more optimal algorithm, it would lead to faster running time.\par
%%%
As it can be seen in column 5 of table \ref{table:runningTime}, the total running time of CT-Index varies from 49 seconds to 114 seconds depending on the specified input parameters. If we look at rows 4 and 5, the only difference of the input parameter values is the fingerprint size. As it can be seen from the table, the time difference to build the index in 4 and 5 is only around 200 miliseconds. However, the time taken to compute the answers from the set of candidates is more than 6 seconds slower in row 5 compared to row 4, although the number of candidates for the two rows are almost the same for every query except query 3. Similar difference can be observed when comparing row 1 with row 6. The reason for these results could be that fingerprint of size 2048 is too small for the particular dataset and this leads to more collisions.\par
%%%
To conclude, in CT-Index, when using only paths as features leads to smaller running time for building index, however it significantly bigger number of candidates and therefore bigger amount of time to find all targets containing the query from the set of candidates. Using trees as features results to an index with much better filtering power, but slower to compute. Hashing features constructed from paths and trees does not give any benefit, moreover, it it slower and results to slightly bigger number of candidate graphs.\par

%%%% TODO write about the experiments with other data sets
%When running the implementation of \cite{ctindex}, we observed that the algorithm never terminated for some instances of pdbs and ppigo. A similar question arises here: it this because the indexing technique is insufficient to eliminate incompatible targets 
% TODO: write the answer of these questions:
% is it because of SIP of ct-index being really bad?
% is it the case that both SIP of ct-index is really bad and the indexing pat also takes a lot of time and is useless? Need to do ct-index data analyzing to be able to answer these questions.
%%% TODO add some plots 
\subsection{gIndex, gCoding .... mention them}
\section{Subgraph Isomorphism Algorithms}
\subsection{Partick and Ciaran's paper}
\subsection{Christine's paper}

\chapter{Path-based query processing algorithms based on filtering-verification }

The order of a graph is the cardinality of its
vertex set. We write V(G) for the vertex set of a graph G.

A non-induced subgraph isomorphism from a graph P
(called the pattern) to a graph T (called the target) is an injective
mapping from V(P)to V(T) which preserves adjacency—
that is, for every adjacent v and w in V(P), the vertices i(v)
and i(w) are adjacent in T. An induced subgraph isomorphism
additionally preserves non-adjacency—that is, if v and
w are not adjacent in P, then i(v) and i(w) must not be adjacent
in T. We use the notation i : P  T for a non-induced
isomorphism, and i : P ,→ T for an induced isomorphism.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Benchmarks %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Benchmarks} %% not sure this is the best name for this 
This section includes more information about the already existing indexing algorithm implementations that were used as a standard point of reference against our graph indexing implementations. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Index algorithms %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% todo move this to where I explain the filter-verification paradigm
\section{Index algorithms}

    All algorithms described in this section generate the candidate set of graphs in the following steps:
    
    \begin{enumerate}
        \label{indexSteps}
        \item Compute the index of all graphs in T;
        \item Compute the index of all patterns in P;
        \item Using the target and pattern indexes computed in the previous two steps, extract all graphs in T that contain all features in the pattern index;
        \item All extracted graphs from step 3 form the candidate set C.
	\end{enumerate}
    
    In this work, we consider only induced subgraphs (definition \ref{def:induced-subgraph} in section \ref{subsec:definitions}) and the induced version of the subgraph isomorphism problem (definition \ref{def:inducedSubgraphIsomorphism} in section \ref{subsec:definitions})
    
    The correctness of the results is checked comparing the answers obtained from CT-Index. We implemented a class called $Verify.java$ that checks whether the resulting candidate set after each query execution contains the answers of subgraph isomorphism. $Verify.java$ was very useful for discovering a lot of bugs during the software development process.
    
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%------------------------- Path Index --------------------------%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Path Index}
\label{path-index}
This section gives an overview of the first indexing technique that was designed and implemented. In following subsections we describe the main idea of the algorithm ans the implementation. The performance results that were obtained after running various types of queries on targets of varying size are described along with a summary of the advantages and limitations of the algorithm.\par
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The idea}
\label{path-index-idea}
    The algorithm uses an exhaustive path-enumeration approach to build its index. This technique is employed by various algorithms like CT-Index \cite{ctindex}, gCode \cite{gcode} and GraphGrepSX \cite{graphgrepsx}. The main idea behind \textit{exhaustive path-enumeration} is to enumerate all existing paths in a database up to $maxL$ length and index them, where a path is a sequence of vertexes such that each vertex is connected with an edge with the previous and the next vertex in the sequence.\par
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   Given a set of target graphs $T$ and a pattern graph $p$, $Path$-$index$ first computes the index of all graphs in $T$ by enumerating exhaustively all paths in every target up to a specified maximum path length $maxL$. The paths are then stored in a file, which is the target$'$s index. The same procedure using the same value of $maxL$ is followed to derive the pattern index. The two files are then used for finding the candidate set $C$ of all graphs in $T$ that have to be checked for subgraph isomorphism with $p$. Using the pattern index, we check which targets contain all paths in the pattern index and filter out all targets that do not have all paths that the pattern does. The rationale behind this filtering method is that if some features of graph $p$ do not exist in a graph $t$, $t$ cannot contain $p$. However, if $t$ contains all features of $p$, this does not meant that $p$ is subgraph of $t$: $t$ can be a \textit{false-positive} and a subgraph isomorphism test needs to be performed on $t$ and $p$ to identify whether $t$ is a \textit{false positive} or it indeed contains $p$. All targets in $T$ that have all paths, extracted from the pattern graph, form the candidate set $C$. All graphs in $C$ are then checked for subgraph isomorphism with $p$. \par
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
As mentioned before, each path is a sequence of vertices of maximum size $maxL$, such that each vertex is connected with an edge with the previous and the next node in the sequence. Each path, extracted from the graph, is stored in the index file in a string representation, derived from the label of each node in the sequence and the label of the edge (if existent) between the node and its neighbors. In this work, we refer to these path string representations as path-strings. To avoid redundancy index comprises of unique path-strings, computed from the paths taking the following points into consideration:
\begin{itemize}
\item Path $a$ is equivalent to its reverse variant $a$-$reversed$, because the graphs in the datasets are undirected, as mentioned above. There is no need to store both $a$ and $a$-$reversed$ in the index, as this would lead to redundancy.
\item Path $a$ is not equivalent to a path $a$-$sorted$, where $a$-$sorted$ is the sorted variant of $a$ in lexicographical order (either increasing or decreasing). Sorting $a$ can change the places of some of the nodes that comprise the sequence, which means that some nodes may have different neighbors in the sorted path. This introduces new edges in $a$-$sorted$ that may not exist in $a$ or in the graph.
\end{itemize}
To avoid redundancy and make the index search faster, only one unique path-string is written to the file for each path and its equivalent path-string variants, derived using the properties mentioned above. We chose to add to the index the lexicographically smaller path-string between a path and its reverse. \par
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   % example for both previous paragraphs%
Let the graph on figure \ref{B2Y5G} be a target graph in $T$ and the graph on figure \ref{CH4} be a pattern graph in $P$, where the number in red next to each node on the two figures denotes the id number of the corresponding vertex. Let $maxL$ be equal to 3. In order to check whether \ref{C5H12} is a candidate for subgraph isomorphism with \ref{CH4}, we first compute the indexes of \ref{C5H12} and \ref{CH4} for the specified maximum path length. The target index consists of the paths on figure \ref{C5H12-paths} and the pattern index contains the paths on figure \ref{CH4-paths}. There is a lexicographically smaller variant of the path-string \textrm{H-C-H}, namely \textrm{C-H-H}. However, no path in the the graph \ref{C5H12} can form such path-string and adding \textrm{C-H-H} to the index file could lead to wrong results.\par
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
\centering
\begin{minipage}[t]{.5\textwidth}
  \centering
  \includegraphics[height=3cm,width=3.3cm]{images/graphs/CH4.png}
  \caption{Pattern graph P}
  \label{CH4}
\end{minipage}%
\begin{minipage}[t]{.5\textwidth}
  \centering
  \includegraphics[height=3cm,width=4.2cm]{images/graphs/B2Y5G.png}
  \caption{Target Graph T}
  \label{B2Y5G}
\end{minipage}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
After candidate extraction, Path-Index returns target graph \ref{B2Y5G} as candidate for subgraph isomorphism with pattern graph \ref{CH4}, as all paths in \ref{CH4}, shown on figure \ref{CH4-paths} are contained in \ref{C5H12}, as it can be seen on figure \ref{C5H12-paths}.\par
%When the set of targets is the same for multiple patterns, the target index is still computed only once and reused. The 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
\centering
\begin{minipage}[t]{.5\textwidth}
  \centering
  \includegraphics[height=3.3cm,width=2.3cm]{images/paths/C5H12.png}
  \caption{Target graph path enumeration}
  \label{C5H12-paths}
\end{minipage}%
\begin{minipage}[t]{.5\textwidth}
  \centering
  \includegraphics[height=2.4cm,width=2cm]{images/paths/CH4.png}
  \caption{Pattern graph path enumeration}
  \label{CH4-paths}
\end{minipage}
\caption{All paths up to maximum length 3}
\label{pathsEnumeration}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Implementation}
\label{path-index:implementation}
\subsubsection{Graph representation}
\label{path-index:graph-representation}
	Each graph is represented with a Java class \textrm{Graph} that has an integer id and a collection of node objects as fields, where the integer is a unique identifier. Each node object has an id, a label and a list of edge objects, where the node is a source node for each edge contained in the list. The length of the list of the edge object is equal to the degree of the node. Therefore, each edge object does not need to keep a record of the source node: it only has a label and a destination node as fields. As the graphs we are working with are not directed, two Edge objects are created to represent an edge. The first object has one of the nodes as destination node and then added in the list of edges of the other node: the source node. The second edge object will have the source node of the first edge object as destination node and included in the list of edges of the destination node of the first edge object, which will be its source node. The label of both edge objects will be the same.\par
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Path Extraction}
\label{path-index:path-extraction}
A class, called \textrm{PathExtractor}, contains all functionality for computing the paths and path-strings that are stored in the index. To compute the index of a given graph dataset, we use the functionality of \textrm{PathExtractor} to extract all paths of every graph in the dataset. The path extraction algorithm is recursive depth-first-search based and is called on every node of the graph. Algorithm 1 describes our approach. Before we call function \textrm{generatePath}, we initialize an empty stack that is used in the algorithm to store visited nodes. \textrm{Algorithm 1} generates all paths in the graph of size $maxL$ , where $maxL$ is the number of nodes in a path, using two functions: \textrm{generatePath} and \textrm{generatePathInner}. The function \textrm{generatePath} in \textrm{Algorithm 1} takes a list of all nodes in the graph and path length $maxL$ as parameters and calls \textrm{generatePathInner} for every node in the list as starting node (line 4). The start node is also pushed on the stack (line 3), as it is part of the path that is to be generated. \par
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[h]
 \centering
 \label{Algorithm 1.}
 \begin{tabular}{l l}
	\textbf{Algorithm 1.} Paths extraction \\\hline
    \small\textbf{1}  \,\small{generatePath(nodes, maxL) $\rightarrow$ void}\\
    \small\textbf{2}  \,\,\,\,\,\,\,\,\small{\textbf{for every} start-node in nodes \textbf{do}:}\\
    \small\textbf{3}  \,\,\,\,\,\,\,\,\,\,\,\,\,\small{push start-node on top of stack}\\
    \small\textbf{4}  \,\,\,\,\,\,\,\,\,\,\,\,\,\small{generatePathInner(node, maxL)}\\
    \small\textbf{5}  \\
    \small\textbf{6}  \,\small{generatePathInner(node, maxL) $\rightarrow$ void}\\
    \small\textbf{7}  \,\,\,\,\,\,\,\,\small{\textbf{if} stack is \textbf{ less or equal to} maxL \textbf{then:}}\\
    \small\textbf{8}  \,\,\,\,\,\,\,\,\,\,\,\,\,\,\small{outputPath(stack)}\\
    \small\textbf{9}  \,\,\,\,\,\,\,\,\small{\textbf{if} stack is \textbf{equal to} maxL \textbf{then:}}\\
    \small\textbf{10} \,\,\,\,\,\,\,\,\,\,\,\,\,\small{remove the topmost element from the stack}\\
    \small\textbf{11} \,\,\,\,\,\,\,\,\,\,\,\,\small{\textbf{exit}}\\
    \small\textbf{12} \,\,\,\,\,\,\,\small{\textbf{for every} neighbor of node:}\\
    \small\textbf{13} \,\,\,\,\,\,\,\,\,\,\,\,\,\small{\textbf{if} neighbor not on stack \textbf{then:}}\\
    \small\textbf{14} \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\small{push neighbor on top of stack}\\
    \small\textbf{15} \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\small{\textbf{generatePathInner}(neighbor, maxL)}\\
    \small\textbf{16} \,\,\,\,\,\,\,\small{\textbf{if} all neighbors are on stack \textbf{and} stack is not empty \textbf{then:}}\\
    \small\textbf{17} \,\,\,\,\,\,\,\,\,\,\,\,\,\small{remove the topmost element from the stack}\\
    \hline
 \end{tabular}%
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%TODO explain lines 7 - 11 and check the correctness of line numbers
The recursive function \textrm{generatePathInner} generates all paths is length $maxL$, where the length of a path is equal to the number of all nodes that are part of it, from a start node $node$. First, the size of the stack is checked. If it is less or equal to $maxL$, the contents of the stack are copied and passed to a function \textrm{putToIndex} that computes the string representation of the extracted path and puts it to the index. If the stack is equal to $maxL$, the last element from the stack is popped out and the function exits. If the size of the stack is less than $maxL$, we traverse the neighborhood of $node$ in the for loop, starting at line 12. Every unvisited neighbor of $node$ is pushed on the stack and then a recursive call to \textrm{generatePathInner} is made with the same neighbor node as $node$(lines 13 and 14).\par
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The stack used in \textrm{Algorithm 1} follows the principles of the stack datastructure. In this work, we use the Java implementation. The stack has two main functions: to keep track of the visited nodes in the current function call so that no node takes part in a path more than twice, i.e. there are no cycles; and it contains nodes that always form a valid path. The reason why this is the case is that every time a node is pushed on top of the stack, this node is one of the neighbors of the last node on the stack. The only place in generatePathInner function where new node is added in the stack is in line 14 and the node that is pushed on top of the stack belongs to the list of neighbors of $node$, which is always the previous node in the stack. Therefore, the sequence of all nodes on the stack forms a valid path, as every node is connected with an edge with its predecessor and successor in the sequence. The complexity of Algorithm 1 is explained in section \ref{path-index:complexity}.\par
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The function \textrm{outputPath} is called by \textrm{generatePathInner} every time the stack reaches a size equal to $maxL$ (line 8, Algorithm 1). Algorithm 2 derives the lexicographically smallest string representation of a path, following the principles described in section \ref{path-index-idea}. The resulting path-string is added to the index, if it does not exist there (line 8, Algorithm 2). \par 
Algorithm 2 takes a sequence of nodes as a parameter, which are the contents of the stack when the stack size is $maxL$ (line 8, Algorithm 1). We derive the path-string of the sequence (line 2) that consists of the node label of every node in nodeSequence and the label of the edge it has with the previous node in the path. If the dataset does not have edge labels, a default character is used as label for every edge. In the previous examples, we use the character $"-"$ (figures \ref{C5H12-paths} and \ref{CH4-paths}). It is important to note that the node labels are ordered in exactly the same way as the nodes in the sequence, for example if a node A is on place \textit{i} in the sequence, the label of A will be at place \textit{i} in the string if the edge labels in the string are not counted (if they are counted, the label of A is at position \textit{i} x \textit{2}).\par
Next steps are to compute the reversed sequence of the path (line 3), its string representation (line 4) and check whether the reversed string is lexicographically smaller then the path-string (line 5). If yes, we assign the path-string to be equal to the reversed string (line 6) and add it to the index, if it is not present there yet (line 8). We do not sort the path-string lexicographically, due to the reasons explained in section \ref{path-index-idea}. The complexity of Algorithm 2 is explained in section \ref{path-index:complexity}.\par
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% output path
\begin{table}[h]
 \centering
 \label{Algorithm 2.}
 \begin{tabular}{l l}
	\textbf{Algorithm 2.} Output path \\\hline
    \small\textbf{1} \,\,\small{outputPath(nodeSequence) $\rightarrow$ void}\\
     \small\textbf{2} \,\,\,\,\,\,\,\,\small{pathStr = nodeSequence.toString()}\\
    \small\textbf{3} \,\,\,\,\,\,\,\,\small{reversedSequence = nodeSequence.reverse()}\\
     \small\textbf{4} \,\,\,\,\,\,\,\,\small{pathStrReversed = reversedSequence.toString()}\\
    \small\textbf{5} \,\,\,\,\,\,\,\,\small{\textbf{if} pathStrReversed $<$ pathStr \textbf{then:}}\\
    \small\textbf{6} \,\,\,\,\,\,\,\,\,\,\,\,\,\,\small{pathStr = pathStrReversed}\\
    \small\textbf{7} \,\,\,\,\,\,\,\,\small{\textbf{if} pathStr \textbf{not in} index \textbf{then:}}\\
    \small\textbf{8} \,\,\,\,\,\,\,\,\,\,\,\,\,\,\small{put pathStr to index}\\
    \small\textbf{9}\,\,\,\,\,\,\,\,\small{\textbf{exit}}\\\hline
 \end{tabular}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%TODO the bug I had initially, how the stack was fixed
% TODO reference Java stack below
% TODO explain about the current maximum path length
% TODO explain isVisited boolean field in the Node class
%Iteration is every new entering to the while loop when we have new start node and we have the stack cleaned up. --- write that properly
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Candidates extraction}
\label{path-index:candidates-extraction}
Candidates extraction is the part of the implementation where the set of candidates $C$ from the dataset with target graphs is constructed. Algorithm 3 describes our approach in more detail. Function \textrm{candidatesExtractor} takes the index of one graph from the target dataset and the index of the pattern (or one of the set of pattern graphs, if there are more than one pattern) as parameters (line 1). For every path-string in the pattern, we check whether it is contained in the target index (line 3). If yes, the algorithm continues, because the target might be a candidate (line 6). Otherwise, if the pattern path-string does not exist in the target index, the program returns false and terminates (line 4). The program goes to line 7 iff all path-strings in the pattern are contained in the target index.\par
The complexity of Algorithm 3 is explained in section \ref{path-index:complexity}. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[H]
 \centering
 \label{Algorithm 3.}
 \begin{tabular}{l l}
 \textbf{Algorithm 3.} Candidates extraction \\\hline
 \small\textbf{1} \small{candidatesExtractor(target-index, pattern-index) $\rightarrow$ \textbf{true} or \textbf{false}}\\
 \small\textbf{2} \,\,\,\,\small{\textbf{for every} pattern-path \textbf{in} pattern-index:}\\
 \small\textbf{3} \,\,\,\,\,\,\,\,\small{\textbf{if no} target-path \textbf{equals} pattern-path \textbf{then:}}\\
 \small\textbf{4} \,\,\,\,\,\,\,\,\,\,\,\,\small{\textbf{return false}}\\
 \small\textbf{5} \,\,\,\,\,\,\,\,\small{\textbf{else:}}\\
 \small\textbf{6} \,\,\,\,\,\,\,\,\,\,\,\,\small{\textbf{continue}}\\
 \small\textbf{7} \,\,\,\,\small{\textbf{return true}}\\
 \hline
 \end{tabular}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Performance}
This section gives more details about the complexity of each of the algorithms in the implementation, explained in sections \ref{path-index:path-extraction} and \ref{path-index:candidates-extraction}, continued with statistics about the algorithm running time and performance after running it on various datasets. Following the results obtained, we make a conclusion about the observed performance of the algorithm and analyze its advantages and disadvantages.\par
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Complexity}
\label{path-index:complexity}
Algorithm 1 works like depth-first search, but the depth of the search has a maximum limit $maxL$. For each target graph, we conduct depth-first search of depth $maxL$. During the search, each neighbor of $maxL$ number of nodes is visited. The worst case complexity is when the target graph is a clique. If we assume that the number of nodes in the clique is n (equal to the number of edges), then the for loop on line 2 will be executed n times, each time calling \textrm{generatePathInner} function. This function will make recursive call for every unvisited neighbor of the current vertex, until the stack reaches size equal to $maxL$. As after every recursive call, the size of the stack is increased by 1 and the graph is a clique, the number of neighbors that will be visited during the next recursive call decreases by 1. The depth of the recursive calls is at most $maxL$ (the maximum size of the path we want  is $maxL$), therefore the function has worst case complexity \textbf{O((n - 1).(n - 2) ... (n - maxL - 1))}, which occurs when the graph is a clique. \par
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 Algorithm 2 does not have any loops, but it calls the function \textrm{toString()}, which traverses the given path once to change each node with its label and an edge label to the next node in the sequence. The \textrm{toString()} method visits every node in the path, takes the label of the current node, and if the dataset has edge labels, finds the edge label of the edge between the current node and the next node, otherwise adds a default character after the node label. On line 7, there is a traversal through the current index of a graph. The complexity of Algorithm 2 is therefore \textbf{O(maxL + index size)}, where index size is the current size of the index for the current graph being indexed. The best case is when the index is empty: then traversing the index takes constant time and the complexity of the \textrm{toString()} method is \textbf{O(maxL)}.\par
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Algorithm 3 visits every path stored in the pattern index and for each pattern path, it goes through the target index and checks whether it contains the same path. This procedure is done for every target graph in the dataset. If we assume that the number of paths in the pattern index is \textit{p}, the number of paths in the current target index is \textit{t} and the number of graphs in the target dataset is \textit{n}, the number complexity of the algorithm is \textbf{O(ptn)}.\par
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experimental Results}
\label{path-index:experimental-results}
TODO


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Advantages and Limitations}
\label{path-index:advantages-limitations}
    TODO\\
    - structural information is lost, because path is too simple\\
	- it is computationally intense, i.e. very slow especially when computing paths of higher length; there are too many paths\\
    - very easy to implement\\
    - paths are easier to manipulate than trees and graphs --- why?\\
    - this indexing technique is good when we have graphs with large number of different labels on their nodes and low density of edges between the graphs' nodes\\
    - the index space is predefined: all the paths up to \texttt{maxLen} length are selected\\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%---------------------- Path-Subtree Index -------------------------%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Path-Subtree Index}
\label{path-subtree-index}
  $Path$-$Subtree$ index is the second indexing technique that was designed, implemented and evaluated. In this section we explain its main idea, implementation and performance, observed after testing with various types of graph data sets. We write about the problems with the algorithm we discovered after the initial implementation and how we changed $Path$-$Subtree$ index to solve the issues encountered. Lastly, we draw conclusions about the advantages and limitations of this indexing technique.  
\subsection{Initial idea}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
As mentioned in section \ref{path-index:advantages-limitations}, $Path$ index can't extract most of the structural information present in the graphs. It is almost of no use for targets that have small number of different labels, like the AIDS data set for example. $Path$-$Subtree$ index addresses the problem of insufficient structural information extraction by introducing a novel representation of the paths that takes into account the neighborhood of each node. A new version of the label of each node that is present in the path is computed and stored in the index instead of the node$'$s original label. In this work, we refer to this alternate label as \textit{neighborhood label}. The next paragraphs introduce necessary naming conventions and then describe what \textit{neighborhood label} means and why we believe it helps to derive a better index.\par %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Let \texttt{n} be a node with neighbors \texttt{N} = $\{$ $n^{}_1$, $n^{}_2$ \ldots $n^{}_i$ $\}$, where \texttt{i} is the size of \texttt{N}. Let us define a labeling function \textit{l} that maps the node \texttt{n} and each node in \texttt{N} to a character, also called the node label. We refer to the label of \texttt{n} as \texttt{$L^{}_n$} and the label of each node $n^{}_j$ in \texttt{N}, where $j$ is between $1$ and $i$ inclusive, as \texttt{$L^{}_j$}. It is important to note that using this notation we do not mean that each node has unique label, i.e. there may exist nodes $n^{}_g$ and $n^{}_h$, where $g$ and $h$ are between $1$ and $i$ inclusive, and \texttt{$L^{}_g$} is the same as \texttt{$L^{}_h$}.\par %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The term \texttt{neighborhood label} is a specific label that is computed for each node in the graph using the label of each node and its neighbors: all nodes, connected with an edge with it. The label derived is then stored in the index file as part of the string representation of the nodes in the paths, similarly to the node labels that are part of the string representations of paths in the previous index algorithm in section \ref{path-index}.\par
The \textit{neighborhood label} of \texttt{n} is derived in the following way. Let the label of \texttt{n} and the labels of all members of \texttt{N} form the set of labels \texttt{S}. The \textit{neighborhood label} of \texttt{n} is constructed using the labels in \texttt{S}, ordered lexicographically from the smallest to the largest label in \texttt{S}. For instance, we take each member of \texttt{S} and derive the sequence \texttt{S$'$} = $s^{}_1$$s^{}_2$$s^{}_3$ \ldots $s^{}_i$, where $i$ is the number of the neighbors of \texttt{n} and consequently the number of members of the set of labels \texttt{S}. \texttt{S$'$} is the resulting \textit{neighborhood label} of \texttt{n}. For example, the \textit{neighborhood label} of each node of the graph on figure \ref{CH4} is shown on figure \ref{CH4-subtree-label-graph}, where the red number on the left side of each node is its id. From figure \ref{CH4} it can be seen that node with id 4 has neighbors nodes 0, 1, 2, 3 each of them with label \texttt{H}. The label of node 4 is \texttt{C} and after appending the labels of its neighborhood, the resulting \textit{neighborhood label} is \texttt{CHHHH}. Similarly, the label of node 4 is part of the \textit{neighborhood label} of the other nodes.\par
%%%
%write an example of the paths derived using this method
%%%
The resulting path-strings from path extraction of \ref{CH4-subtree-label-graph} for $maxL$ equal to 3 are shown on figure \ref{CH4-subtree-label-paths}, where the the character $"-"$ denotes an edge. It is important to note that although the path representation stored in the index file is changed, the original node labels of the graph are not removed so that the structure and labeling remains unchanged. Also, the paths on figure \ref{CH4-subtree-label-paths} are composed from the same nodes as the paths of figure \ref{CH4-paths}. The difference of the representation comes only from the alternative labeling model. The method of extracting the paths remains the same as the one used for $Path$ index and described in section \ref{path-index}. Similarly, computing the set of graphs possibly subgraph isomorphic to a pattern graph \texttt{p}, also called the \textit{candidate set}, is done using the same method as $Path$ index.\par
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Like $Path$ index, $Path$-$Subtree$ index supports graphs that have labels on edges and nodes. When deriving the representation of each path that is later stored in the index, we include the label of the edge that connects every two nodes \texttt{a} and \texttt{b} that are part of the path. If we take the graph on figure \ref{CH4-subtree-label-graph}, we notice that there are no labels of its edges. Consequently, the paths stored in the target index, also shown on figure \ref{CH4-subtree-label-paths} have the character $"-"$ between the \textit{neighborhood label} of each two nodes. If graph \ref{CH4-subtree-label-graph} had edge labels, we would include the corresponding label instead of $"-"$. \par  
%%%%%%%%%%%%%%%%% WHY IS NEIGHBORHOOD METHOD BETTER? %%%%%%%%%%%%%%%%%%%
\begin{theorem}
The set of target graphs filtered by path index is always a subset of the targets filtered by path-subtree index.
\end{theorem}

\begin{proof}
Prove this

\end{proof}


- the path extraction is done in the same way only labels are changed


%%%
With the following example we show that $Path$-$Subtree$ index discriminates graphs that $Path$ index can not. Let us consider the graphs on figure \ref{C2H6} and \ref{CH4}. Let \ref{C2H6} be the target graph and \ref{CH4} to be the pattern. Before running the subgraph isomorphism test on the two graphs, we will index them and see whether we can filter out \ref{C2H6}. As we can see, \ref{C2H6} does not contain \ref{CH4} and we are going to check whether Index-2 will return the target graph as a false-positive candidate for subgraph isomorphism with our pattern. After computing the indexes of the two graphs, we get the results for \ref{C2H6} shown on figure \ref{C2H6-subtree-label-paths} and the results for \ref{CH4} on figure \ref{CH4-subtree-label-paths}. As we can see from the figures, the index of our pattern graph has paths that the target does not contain, for example \texttt{CHHHH, CH-CHHHH, CH-CHHHH-CH}. The target graph is not returned as a candidate for subgraph isomorphism. Computing the index using $Path$ index results in getting the paths, displayed on figure \ref{C2H6-paths} for our target graph \ref{C2H6} and the paths on figure \ref{CH4-paths} for the pattern. As all paths of \ref{CH4} are contained in the index of \ref{C2H6}, $Path$ index returns \ref{C2H6} as candidate for subgraph isomorphism.\par
%%%
\subsection{Problems with Path-Subtree index}
\label{path-subtree index problems}
After we implemented $Path$-$Subtree$ index based on the principles described in the previous subsection, we discovered that our algorithm is wrong. Apart from the expected false positives, it had false negatives. False negatives in this case are target graphs that contain the pattern, but are wrongly filtered out after the graph indexing step and are never included in the candidate set. The existence of false negatives is strongly undesired, as it is an indication that the indexing algorithm is wrong and therefore useless. We discovered what the reason for discarding targets wrongly is. In the following paragraphs we explain in more details the problem using a worked example and propose a modification of the algorithm that has the potential to solve the issue.\par
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Let the graph on figure \ref{C2H6} be our target graph and the graph on figure \ref{C2H3} be the pattern. As we can see from the two figures, \ref{C2H6} contains \ref{C2H3} and we expect that a correct indexing technique will return \ref{C2H3} as a candidate for subgraph isomorphism check. After computing the indexes of the target and the pattern graphs, we derive the results for the target, shown on figure \ref{C2H6-subtree-label-paths}, and for the pattern, shown on figure \ref{C2H3-subtree-label-paths}. As we can see from the two figures, although the target contains the pattern, the paths in their indexes are different. As the target index does not contain paths existent in the pattern index, like \texttt{CC, CC-CCHHH} and \texttt{CH-CCHHH-CC} for instance. In this case, \ref{C2H6} is a false negative, discarded wrongly because of our incorrect indexing technique.\par
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[h]
  \begin{minipage}[t]{.5\textwidth}
    \centering
    \includegraphics[height=3.3cm,width=3.7cm]{images/graphs/C2H3.png}
    \caption{Pattern graph}
    \label{C2H3}
  \end{minipage}
  \begin{minipage}[t]{.5\textwidth}
  \centering
  \includegraphics[height=3.9cm,width=3.8cm]{images/paths/C2H3-isomer-paths.png}
  \caption{Subtree-label paths}
  \label{C2H3-subtree-label-paths}
  \end{minipage}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Algorithm Refinement}
  In order to solve the problem with false negatives, we changed the candidate extraction part. For every path $pp$ in the pattern index, we check which target graphs contain $pp$ as a path. Let us have $pp$ = \texttt{CH-CCHHH} and we want to check it against the target path $tp$ = \texttt{CH-CCCHHH-CHHH}. For every \textit{neighborhood label} in $pp$, our algorithm will whether it is contained in the corresponding label in $tp$. We first compare \texttt{CH} and \texttt{CH}, and as they are equal, we continue with the labels on the next position: \texttt{CCHHH} and \texttt{CCCHHH}. As \texttt{CCCHHH} contains \texttt{CCHHH} and this is the last label in $pp$, we stop and return true, $tp$ contains $pp$.\par
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using the refinement described above, we removed the problem with false negatives, described in section \ref{path-subtree index problems}. However, this results in weaker filtering power. Now, there are some cases where $path$-$index$ would perform better, although it extracts less structural information about the graphs. We will show how our refined method introduces more false-positives using an example. Let us consider the two graphs on figures \ref{C2H4-1} and \ref{C2H}. Let us apply the refined $Path$-$Subtree$ indexing method for the two graphs, where \ref{C2H} is the pattern and \ref{C2H4-1} is the target (clearly, \ref{C2H4-1} does not contain \ref{C2H} as subgraph). The \textit{neighborhood labels} of the target and the pattern for $maxL$=3 are shown on figures \ref{C2H4-1-subtree-label-paths} and \ref{C2H-subtree-label-paths} respectively. Applying the new candidate extraction technique, we will have \ref{C2H4-1} returned as candidate, because it contains all paths in \ref{C2H}.\par
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
\begin{figure}[h]
\centering
\begin{minipage}[t]{.5\textwidth}
  \centering
  \includegraphics[height=3.3cm,width=4.4cm]{images/graphs/C2H4-1.png}
  \caption{Graph A}
  \label{C2H4-1}
\end{minipage}%
\begin{minipage}[t]{.5\textwidth}
  \centering
  \includegraphics[height=1cm,width=3cm]{images/graphs/C2H.png}
  \caption{Graph B}
  \label{C2H}
\end{minipage}%

\begin{minipage}[t]{.5\textwidth}
  \centering
  \includegraphics[height=4.4cm,width=3.9cm]{images/paths/C2H-isomer-paths.png}
  \caption{Neighborhood label paths of A}
  \label{C2H4-1-subtree-label-paths}
\end{minipage}%
\begin{minipage}[t]{.5\textwidth}
  \centering
  \includegraphics[height=2.1cm,width=2.7cm]{images/paths/C2H-isomer-paths.png}
  \caption{Neighborhood label paths of A}
  \label{C2H-subtree-label-paths}
\end{minipage}%
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Let us examine in more detail the only path of length 3 in the pattern graph. It is composed from the nodes with ids \texttt{0, 1} and \texttt{2}. Using $Path$-$Subtree$ index method, this path is represented as \texttt{CH-CCH-CH} in the index file. If we used $path$-$index$, we would store this path as the string \texttt{C-H-C}. Although the path representation \textit{neighborhood label} gives us more information about the node neighbors, with us we loose important structural information, which is: the label of the actual node. In the string \texttt{CCH},  either of the letters could be the label of the node. As shown in the example above, this confusion leads to more false positives.\par
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
TODO
  - we changed the string representation of the isomer label. First letter is always the original label, the others are from the neighbors, sorted in lexicographic order\\

\subsection{Implementation}
       
       - extend IB-Index 1 and put an option to extract paths using isomer labels.\\
       - describe the extension of the project to support both types of indexing.\\
       - when parsing the graphs, after parsing each graph, compute the isomer label of every node for this graph\\
       - additional field in Node class for isomer labels\\
       - we have a class Path to represent the paths. Each path is an array of nodes. There is a toString method that returns the desired string that we are to store in the index. Depending on the option, we can return path from the labels (ib-index 1), path from the isomer labels (ib-index 2) or a path from the id of each node, made for testing purposes There is a method to reverse the path and it is used when storing the paths in the index: we always store the lexicographically smaller path, comparing each path with its reversed equivalent.\\
       - re-written the candidates extraction part. We have to check for containment ... \\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
\subsection{Performance}
TODO \\
       - the index file is bigger, but the candidate set is smaller\\
       - put the table with results\\
       - explain the results and why they are like this\\
	   - complexity?\\
 	   - what could be done better and how?\\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Variants of Path-Subtree index}
TODO \\
 %- use neighborhood of length 2, 3 ...
 %- this will result in bigger index, but even stronger filtering strength, which means
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Advantages and Limitations}
TODO \\
 - very easy to implement, especially when we have index-1 implementation ready\\
 %- the index file is even bigger --- this is  bad\\
 
 
 
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%------------------------------SIP Algorithms--------------------------%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% todo
%% remove sip0 and make sip1 be sip 0
%% make the graphs be in log scale
\chapter{Light Filters}   
This section describes the study of a simple subgraph isomorphism problem algorithm with a fast filter implemented on top of it. The algorithm is called SIP1 and it is explained below. We present the experimental evaluation conducted to find out more about the effectiveness of light filtering, the notion of search effort and how it is affected depending on the nature of the datasets and the yes/no answer of the SIP. Finally, the results of the experiments are reported.

\subsection{SIP1}
SIP1 is based on the simplest of the Glasgow algorithms \cite{CP2015}. Given a pattern and a target graph $P$ and $T$ respectively, SIP1 has a variable for each vertex in $P$, each with domain that is the set of compatible vertices in $T$. Compatible vertices have the same labels and the degree of the target vertex is greater than or equal to the degree of the pattern vertex. Bit sets are used to represent the domains and the adjacency matrices of the graphs. When a pattern variable $u$ is instantiated with a target value $i$, all variables have $i$ removed from their domains. Also, if a future variable $v$ is adjacent to $u$ in P then the domain of $v$ is the intersection of the current domain of $v$ with the neighborhood of vertex $i$ in $T$. This constraint is enforced by applying a logical $and$ operation between the two bit sets. SIP1 uses fail-first heuristic. For all instantiated variables representing pattern vertices, it selects to explore the one that has the smallest domain before the others.

At the top of the search, 5 naive tests are performed to determine whether the two graphs are compatible. If the conditions of the tests are not met, search does not proceed and we consider this to be a $trivial$ $fail$. These tests are presented on table \ref{table:failures}. The neighborhood degree sequence (NDS) of a graph and a label degree sequence (LDS) is used for most of the tests. In the next section, we define and explain the notion of NDS and LDS and their implementation.

\subsubsection{Neighborhood Degree Sequence}
NDS and LDS are defined as follows.

\begin{definition}[Label Degree Sequence]
Given a graph $G(V,E,L)$ with $V$ the set of vertices, $E$ the set of edges and $L$ the set of labels, the LDS of $l$ $\in$ $L$ is a non-increasingly ordered list of the degrees of all vertices in $V$ that have $l$ assigned as their label.    
\end{definition}

\begin{definition}[Graph Neighborhood Degree Sequence]
Given a graph $G(V,E,L)$ with $V$ the set of vertices, $E$ the set of edges and $L$ the set of labels, the GNDS of $G$,  also written as NDS(G), is the list of tuples (l,LDS(l)) for every label l $\in$ $L$.
\end{definition}

\begin{example}
Let us consider again the graph on figure \ref{B2Y5G}. There are three distinct labels: yellow (Y) blue (B) and green(Gr). Nodes 1, 2, 3, 4 and 6 are Y and each of them has deg 1. Nodes 7 and 8 are B, both of degree 4. 5 is the only Gr node. Therefore, the LDS of the labels are as follows.
\begin{itemize}
\item LDS(Y) = $<$1, 1, 1, 1, 1$>$
\item LDS(B) = $<$4, 4$>$
\item LDS(Gr) = $<$1$>$
\end{itemize}
The NDS(graph \ref{B2Y5G}) consists of the tuples $<$Y, LDS(Y)$>$, $<$B, LDS(B)$>$ and $<$Gr, LDS(Gr)$>$. 
\end{example}

The notion of graph neighborhood degree sequence is used to filter out targets that are incompatible with the pattern. A target graph T is compatible with a pattern graph P if the following two conditions are true:
\begin{itemize}
\item The set of labels in P is a subset of the set of labels in T
\item NDS(P) is a subset of NDS(T)
\end{itemize}

The second condition can be formally defined as follows.

\begin{definition}[NDS(P) is a subset of NDS(T)]
\label{ndsPsubsetndsT}
Let us write DS($l_P$) for the DS(l) $\in$ P and LDS($l_T$) for the LDS(l) $\in$ T, where l is a label both in T and in P. For every such l, every element on position $i$ in LDS($l_P$) is $\leq$ to the element in position $i$ on LDS($l_T$) for 1$\geq$i$\leq|$LDS($l_P$)$|$.
\end{definition}

\begin{example}
Let us consider the subgraph isomorphism problem with T the graph on figure \ref{B2Y5G} and P the graph on figure \ref{CH4}. The set of labels in P, denoted as $l_P$, is composed of B and Y; and the set of labels in T, denoted as $l_T$, consists of B, Y and Gr. Clearly, $l_P$ $\subseteq$ $l_T$. Therefore, the first compatibility condition for this example is true.\\
Looking at the LDS of each l $\in$ $l_P$, it satisfies definition \ref{ndsPsubsetndsT}. For example, for l=B, LDS($l_P$) has only 1 element, which is 4 at position 1, and looking at LDS($l_T$), the element at position 1 is also 4.
\end{example}

The defined compatibility conditions are the two new tests added to SIP1. In the next subsection, we explain the implementation details of NDS.  

\subsubsection{NDS and LDS Implementation}
To accommodate the notion of NDS in the SIP algorithm, we added a class called Label to represent every label in the graph and its LDS. We made slight changes to the class representing the graphs, called Graph, and finally we created a class called SIP1 which implements the same subgraph isomorphism algorithm like the easiest SIP algorithm used in \cite{CP2015}. It has additional trivial failures added on the top of the search to check the NDS compatibility between the target and the pattern. Below, we explain the changes for each of the three stated classes.

\begin{itemize}
\item Class Label\\
Every label object has a name of type String and a DS which is an array of integers, sorted in non-increasing order. The degree sequence array is built by inserting the degree of each node with the corresponding label, i.e. building the sorted list incrementally.
\item Class Graph\\
A new field of type array of Labels is introduced to keep a record of all unique labels in the graph. While reading in the graph, we build the array of Labels, creating a new object for each unique label and building its degree sequence as explained above.
\item Class SIP1\\
This is the class that is called for every (p,t) pair of the dataset to check whether t contains p, i.e. this is the part of the code that solves the subgraph isomorphism problem for every such (p,t) pair.

We have added 5 trivial failures on top of the search, which can be seen in table \ref{table:failures}. They are added into the code as if statements in the same hierarchical order as shown in the table. If any of these failures is true, the algorithm terminates returning false (i.e. the corresponding (p,t) instance is not satisfiable, because it is impossible for t to contain p). For example, if the order of t is smaller than the order of the p (trivial fail 1 \ref{table:failures}), SIP1 terminates without going into the search and without taking any other trivial failure tests into an account. 
\end{itemize}

%% TODO: COMPLEXITY!!!!!!!

\subsubsection{Trivial failures hierarchy}
In this subsection, we discuss on the choice of the trivial failures hierarchical structure.

\begin{itemize}
\item Filter 2 and 3 filter differently. Ex: p = \{A,B,B,C\} and t=\{A,B,C\}. Test 2 passes, but test 3 fails
\item There is no need to check whether the length of all labels in T is bigger of equal to the length of all labels in t, because test 2 and 3 would fail if this was not the case.
\item test 4 contains tests 2 and 3.$Explain why$ Furthermore, the notion of NDS introduced those 3 tests. We decided to have them instead of 1 big test to check the effectiveness of each part of the NDS filtering. 
\end{itemize}


%%% todo: make a discussion about the dependency between these failures, i.e. what happens if we switch off one failure or not. Write an informal proof about it?

%%%% table about failures %%%%
\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.5}% Spread rows out...
\begin{tabular}{ >{\centering\bfseries}m{1in} >{\centering\arraybackslash}m{2.3in}} 
\toprule
  Trivial Fail & Meaning\\
\midrule
 \textbf{1} & T.order $\geq$ P.order\\
 \rowcolor{Gray}
 \textbf{2} & T unique labels $\geq$ P unique labels\\
 \textbf{3} & P labels $\subseteq$ T labels\\
 \rowcolor{Gray}
 \textbf{4} & NDS(P) $\subseteq$ NDS(T)\\
 \textbf{5} & initial domain cardinality $>$ 0\\
 \bottomrule
\end{tabular}
\caption{Specification of the measured failure types}
\label{table:failures}
\end{table}        
%%%%

\subsection{SIP Algorithms evaluation}
%%% TODO make graphs with the running time in milliseconds
%%% maybe add tables for each dataset how long it took to solve it in total, how long it took to solve the hardest instance, how long it took to solve the easiset instance, avg time per instance, median time 
%%% do the same table for search nodes?

This section reports on the observed performance of SIP0 and SIP1 when used with the four Big Data datasets.

The experiments are conducted on a Windows 7 SP1 host with 2 Intel Xeon E5-2660 CPUs (2.20GHz, 20MB Cache, 8 cores/16 threads per CPU) and 128GB of RAM, also used by \cite{foteini}. The datasets as the same as described in section \ref{sec:datasets}. All of them are used for evaluation on indexing performance by \cite{foteini, graphgrepsx, GRAPES} and only the dataset called ``aids" is used by \cite{graphgrepsx, ctindex, gcode, tree+delta>=graph}.

When given a set of targets T and a set of pattern P, the program reads in every t $\in$ T and every p $\in$ P and performs a SIP algorithm for each (pattern,target) pair. Run time is measured in miliseconds from when the process starts until it completes, including the time to read in all the graphs, performing all SIP tests and write out all results to a file. As stated previously, both SIP0 and SIP1 implementations are written in Java.

%%%% Analysis of the plots:
\subsubsection{Trivial Failures}
This subsection reports on the total filtering strength of the measured trivial failures with SIP0 and SIP1 algorithms. Table \ref{table:failures} shows in which order they are executed (from 1 to 5) for each SIP algorithm.

While running the SIP for each dataset, every time a trivial failure was observed, we recorded its number using the scale on table \ref{table:failures}. Then, we computed the number of occurrences of each failure for each dataset. These numbers were then used to derive the percentage of the targets that each trivial failure eliminated when executed in the stated hierarchical order. Figure \ref{averageFailures} shows the results with SIP0 (on the left) and SIP1 (on the right). Here, average percent of filtering for each failure is plotted. Additional plots that present the median, maximum and minimum percent of trivial failure filtering can be viewed from the appendix section.

It is important to note that as the failures are executed in hierarchical order, the number of graphs filtered by trivial fail $x$ can depend on the order of execution of $x$ with regards to the other trivial failures. With the results presented, we do not aim to make conclusions on individual performance of trivial failures. In order to study this, alternative set of experiments needs to be conducted.

%%% 
\begin{figure}[h]
\centering
\includegraphics[height=14cm,width=13cm]{images/plots/sip1avgFails.png}
\caption{Average filtering percentage of each method in table \ref{table:failures} for each of the datasets}
\label{averageFailures}
\end{figure}
%%%

While running the experiments, the following observations were made:
\begin{itemize}
\item The trivial failures studied perform best on the aids dataset.\\
In particular, almost 70\% of the targets are removed without making a call to SIP. Only on checking the order of the graphs (trivial fail \#1) and the number of different labels (trivial fail \#2), one is able to prove almost 14\% of all targets as not satisfiable.   
\item All trivial failures measured do not work well on all graphs in pdbs. Similarly, only 3.75\% of the targets were filtered in ppigo.\\
In other words, SIP call was made for every pattern and target graph in the dataset, because they were compatible with respect to every condition on table \ref{table:failures}. There are two possible reasons for this. First, most of the instances of pdbs and ppigo might be satisfiable. If this is the case, there is nothing that can be filtered out. A second reason for these results could be that the trivial fails are not strong enough to eliminate targets from these datasets. Further investigations of the results need to be conducted to find out the reason for the obtained results and identify possible strategies to make SIP algorithms perform better.
\item For some datasets (aids), NDS compatibility tests manage to filter some targets that are otherwise not filtered by the tests 1,2 and 5. For other datasets (pcms), NDS filter out part of the targets that are otherwise removed by a next trivial failure.
\item NDS compatibility does not help eliminating targets before the search for pdbs and ppigo datasets.
\item The dataset that shows best filtering improvement after adding failures 3 and 4 is aids.
\item There are duplicate target graphs in the pcms and pdbs datasets.\\
The pcms database is supposed to contain 200 targets \cite{datasets}. In practice, there are only 50 unique graphs and each of them is added 4 times. The pdbs dataset is composed of 600 targets \cite{datasets}, but out of them only 30 are unique, each of them duplicated 20 times.
\end{itemize}

\subsubsection{Hardness of SIP in terms of search nodes}

%%% todo: what does number of search nodes mean? What is search nodes?

We report on the cost of call to SIP in terms of the number of nodes (a measure of search effort) taken to solve an SIP instance. For every dataset T, for every (P,T) pair, we find every graph t $\in$ T that was not filtered by any of the trivial failures (i.e. all target graphs for which a call to SIP had to be made to check whether the pattern is contained in the target). We compute the number of graphs $|T_i|$ that are solved in given number of nodes $i$ for $0$ $<$ $i$ $<$ $maxN$, where $maxN$ is the maximum number of nodes taken to solve an instance for a given dataset. Figures \ref{aidsNodes}, \ref{pcmsNodes}, \ref{pdbsNodes} and \ref{ppigoNodes} present our results. Here, $|T_i|$ is represented as percentile of all targets (the x-axis). The search effort is plotted, starting from the easiest percentile (the leftmost part of the x-axis) and finishing with the last percentile representing the hardest instances in terms of search effort (on the rightmost part of the x-axis). The y-axis shows the cumulative difficulty of SIP calls in terms of search nodes for each percentile of the targets in a log scale. For example, looking at figure \ref{aidsNodes}, 24\% of the targets are solved by using at most 2 nodes, 50\% of all targets are solved in less than 10 nodes. The hardest instances take at most 600 nodes.

The value on the y-axis for each percentile of T represents the number of nodes taken to solve the hardest instance that belongs to the percentile. In other words, the graphs below show the hardest instance observed for each percentile of T. For example, if we had 3 graphs that belong to the i$^{th}$ percentile of T and they were solved in 1, 2 and 10 nodes respectively, the y-axis value of i would be 10. Therefore, the datasets are in practice easier than what is shown on figures \ref{aidsNodes}, \ref{pcmsNodes}, \ref{pdbsNodes} and \ref{ppigoNodes}, which present the hardest instance for each percentile in the dataset.

We derived the number of members of 1 percent of all target graphs in T by dividing |T| by 100. In cases with aids and pcms, the number of targets in the dataset was not divisible by 100. This is why for these datasets, the last percentile is slightly bigger with respect to the number of targets that form each of the rest 99\% of the graphs.

The plots below help us to make the following observations:
\begin{itemize}
\item The easiest dataset is ppigo. Looking at figure \ref{ppigoNodes}, 88\% of all targets are solved by using at most 4 nodes, 28\% are solved by using at most 1 node of search effort. The hardest problem (the right-most bar) takes 65 nodes to solve and it is between pattern ``8\_1.6" and target ``\#MUS$/$Mus\_musculus.sif$>$0.5.sif". The time taken to solve this is 4 milliseconds and the instance is unsatisfiable.

\item The dataset called pdbs is the harder compared to ppigo and and aids and the most versatile one in terms of search effort. It is on average harder than pcms, however, the hardest instance in pcms takes more search effort than the hardest instance in pdbs. Figure \ref{pdbsNodes} shows that 20\% of the targets in pdbs are solved by using at most 100 nodes, which is significantly higher than ppigo, where even the hardest instance was solved in less than 70 nodes. The hardest instance here is between pattern ``32$\_$1ARO" and target ``\#g" and it is solved in 7152 nodes for 95 milliseconds. This instance is not satisfiable. 

\item The dataset with the hardest instance is pcms. The hardest SIP takes 10470 nodes to solve and it is between pattern ``16\_1C5G.cm.A" and target ``1CY2.cm.A.cmap". It was solved in 12 milliseconds and it is unsatisfiable. Looking at the other 99\% of pcms targets, we can see that they are mostly easy. For example, 43\% of the SIP instances are solved by using at most 10 nodes of search effort.

\item The aids dataset is comparably easy. The maximum nodes taken to solve a SIP instance took 619 nodes of search effort. Namely, it is the SIP call between pattern \#1 and target \#629591 and it took 0 milliseconds of time. SIP(\#1,\#629591) is not satisfiable.

\item Looking at aids, pcms and pdbs, the number of nodes taken to solve SIP grows exponentially with the percentile of the population.

\item The hardest instance of each dataset is not satisfiable.

\item Even the hardest instance of each dataset is solved very quickly.
\end{itemize}

%%%
\begin{figure}[h]
\centering
\begin{minipage}[t]{.5\textwidth}
  \centering
  \includegraphics[height=11cm,width=9cm]{images/plots/aidsPercentileLog.png}
  \caption{SIP on aids dataset}
  \label{aidsNodes}
\end{minipage}%
\begin{minipage}[t]{.5\textwidth}
  \centering
  \includegraphics[height=11cm,width=9cm]{images/plots/pcmsPercentileLog.png}
  \caption{SIP on pcms dataset}
  \label{pcmsNodes}
\end{minipage}
\end{figure}
\begin{figure}[H]
\centering
\begin{minipage}[t]{.5\textwidth}
  \centering
  \includegraphics[height=11cm,width=9cm]{images/plots/pdbsPercentileLog.png}
  \caption{SIP on pdbs dataset}
  \label{pdbsNodes}
\end{minipage}%
\begin{minipage}[t]{.5\textwidth}
  \centering
  \includegraphics[height=11cm,width=9cm]{images/plots/ppigoPercentileLog.png}
  \caption{SIP on ppigo dataset}
  \label{ppigoNodes}
\end{minipage}
\end{figure}
%%%%

\subsubsection{Hardness of SAT vs UNSAT SIP instances}

The observation that the hardest instance of each dataset is not satisfiable arises the following question: is UNSAT SIP generally harder than SAT SIP or are our observations due to pure chance? The experiments described in this section are again conducted in terms of number of search nodes and they are intended to further investigate this observation.

The following eight graphs below break each of the graphs discussed in the previous section (namely \ref{aidsNodes}, \ref{pcmsNodes}, \ref{pdbsNodes} and \ref{ppigoNodes}) further down in terms of whether the SIP instances are satisfiable or not. The blue plots represent all satisfiable SIP pairs (p,t) for every t $\in$ T and every p $\in$ P, where T and P are the sets of targets and patterns for a given dataset D. Similarly, the red plots represent all unsatisfiable SIP (p,t) instances of a dataset D. For each D (namely, for aids, pcms, pdbs and ppigo), the union of the blue plot (satisfiable instances, left-hand side below) and the red plot (unsatisfiable instances, right-hand side below) gives the plot for the corresponding dataset discussed in the previous section. For example, figure \ref{aids:SAT} $\cup$ figure \ref{aids:UNSAT} = figure \ref{aidsNodes}.

Note that figures \ref{ppigo:SAT} and \ref{ppigo:UNSAT} contain only 4 bars each of them, i.e. the data is divided into quartiles instead of percentile. Here, each bar represents 25\% of all instances for the corresponding category (SAT/UNSAT). For example, figure \ref{ppigo:SAT} that represents all satisfiable SIP instances shows that the lowest quartile of the SAT SIP calls takes no more than 4 nodes to solve, as it is also true for the second quartile. We changed the percentile representation for this dataset, because the number of SAT and UNSAT SIP instances is too small to be scaled to percentiles.

%%% todo: maybe make null hypothesis about SAT/UNSAT hardness and try to reject it (or not)?

%%% SAT vs UNSAT in terms of search nodes
\begin{figure}[h]
\centering
\begin{minipage}[t]{.5\textwidth}
  \centering
  \includegraphics[height=11cm,width=9cm]{images/plots/aidsSAT.png}
  \caption{Search effort for SAT aids targets}
  \label{aids:SAT}
\end{minipage}%
\begin{minipage}[t]{.5\textwidth}
  \centering
  \includegraphics[height=11cm,width=9cm]{images/plots/aidsUNSAT.png}
  \caption{Search effort for UNSAT aids targets}
  \label{aids:UNSAT}
\end{minipage}
\end{figure}
\begin{figure}[H]
\centering
\begin{minipage}[t]{.5\textwidth}
  \centering
  \includegraphics[height=11cm,width=9cm]{images/plots/pcmsSAT.png}
  \caption{Search effort for SAT pcms targets}
  \label{pcms:SAT}
\end{minipage}%
\begin{minipage}[t]{.5\textwidth}
  \centering
  \includegraphics[height=11cm,width=9cm]{images/plots/pcmsUNSAT.png}
  \caption{Search effort for UNSAT pcms targets}
  \label{pcms:UNSAT}
\end{minipage}
\end{figure}
\begin{figure}[H]
\centering
\begin{minipage}[t]{.5\textwidth}
  \centering
  \includegraphics[height=11cm,width=9cm]{images/plots/pdbsSAT.png}
  \caption{Search effort for SAT pdbs targets}
  \label{pdbs:SAT}
\end{minipage}%
\begin{minipage}[t]{.5\textwidth}
  \centering
  \includegraphics[height=11cm,width=9cm]{images/plots/pdbsUNSAT.png}
  \caption{Search effort for UNSAT pdbs targets}
  \label{pdbs:UNSAT}
\end{minipage}
\end{figure}
\begin{figure}[H]
\centering
\begin{minipage}[t]{.5\textwidth}
  \centering
  \includegraphics[height=11cm,width=9cm]{images/plots/ppigoSAT.png}
  \caption{Search effort for SAT ppigo targets}
  \label{ppigo:SAT}
\end{minipage}%
\begin{minipage}[t]{.5\textwidth}
  \centering
  \includegraphics[height=11cm,width=9cm]{images/plots/ppigoUNSAT.png}
  \caption{Search effort for UNSAT ppigo targets}
  \label{ppigo:UNSAT}
\end{minipage}
\end{figure}
%%%%

Table \ref{table:SATUNSATnodes} presents statistics in terms of the search effort for satisfiable (blue columns) and unsatisfiable (red columns) instances. We calculated the total number of nodes taken to solve all SIP instances for every dataset, the average, median, maximum and minimum number of nodes taken per instance. For instance, the table shows that the total number of nodes taken to solve all satisfiable SIP instances for the aids dataset is 437 108, whereas the total number of nodes taken to solve all unsatisfiable SIP instances is 2 295 724 nodes, which is almost 5 times more. Using these figures, we derive that the total number of nodes taken to solve all SIP instances for the aids dataset is the sum of those two numbers, which is equal to 2 732 832 nodes.

Looking at the SAT and UNSAT figures and the table, we notice that:
\begin{itemize}
\item For three of the datasets, namely aids, pcms and ppigo, the easiest and hardest instances tend to be UNSAT.
\item For pdbs, there is a big difference in terms of search effort between SAT and UNSAT problems. For example, the satisfiable instances are easier for every percentile of the targets than the unsatisfiable instances (\ref{pdbs:SAT}, \ref{pdbs:UNSAT}). The tabulated results on figure \ref{table:SATUNSATnodes} show that on average, SAT instances are 3 times easier than UNSAT, the SAT median is more than 4 times smaller than the UNSAT instances median and the number of nodes taken to solve the hardest SAT instance is 2 845 which is 4307 nodes less than UNSAT.
\item Table \ref{table:SATUNSATnodes} shows that the total search effort taken to solve unsatisfiable problems is bigger (894 260 nodes taken in total for SAT and 854 720 nodes in total taken for UNSAT problems) contrary to what we observed on the figures. The reason for these results is that pdbs contains large number of solvable instances. In particular, the figures on table \ref{table:dataSAT} show us that the average percent of satisfiable (p,T) SIP instances, where p $\in$ P, is 69.42 (i.e, for each set of (p,T) SIP problems, for 69.42\% of all (p,t) pairs, where t $\in$ T, t contains p as subgraph). Similarly, the median, minimum and maximum number of SAT instances for a set of (p,T) SIP problems are respectively 83.3\%, 22.67\% and 96.7\%. Therefore, the large search effort of SAT SIP problems for pdbs is due to their substantially larger number compared to UNSAT problems. 
\item There is a substantial difference in terms of search effort between the hardest SAT and the hardest UNSAT instances of the pcms dataset. In particular, this difference is 10 092 nodes, where the hardest SAT problem takes 378 nodes (\ref{table:SATUNSATnodes}) and it is between pattern \#32\_1CY1.cm.A.out and target \#1CY0.cm.A.cmap, solved for 4 milliseconds.
\item For aids and pcms datasets, all unsatisfiable instances in total are about 5 times harder than the total number of all satisfiable instances (\ref{table:SATUNSATnodes}).
\item For datasets pdbs and ppigo, the total search effort for unsatisfiable instances is smaller than the search effort for satisfiable SIPs. In particular, for ppigo, it is twice smaller.
\item As noted before, the maximum search effort is always bigger for unsatisfiable instances. For some datasets, the difference is substantial (pcms). For all four datasets, the search effort for the hardest SAT instance is at least twice easier than the search effort taken for the hardest UNSAT instance. 
\end{itemize}


\newcolumntype{g}{>{\columncolor{red!15}}r}
\newcolumntype{b}{>{\columncolor{blue!15}}r}
\begin{table}[H]
\centering
        \renewcommand{\arraystretch}{1.5}% Spread rows out...
        \begin{tabular}{c|bg|bg|bg|bg|bg|}
            \cline{2-11}
            &
             \multicolumn{2}{c}{\textbf{Total}} & 
             \multicolumn{2}{|c}{\textbf{Average}} & 
             \multicolumn{2}{|c|}{\textbf{Median}} & 
             \multicolumn{2}{c}{\textbf{Minimum}} & 
             \multicolumn{2}{|c|}{\textbf{Maximum}} \\
              \hline
            \cline{2-11}
             \hline
            % & SAT & UNSAT & SAT & UNSAT & SAT & UNSAT & SAT & UNSAT & SAT & UNSAT\\
            \multicolumn{1}{|c|}{\textbf{aids}}  &437 108  &2 295 724 &20.998 &10.473   &13  &0   &9  &0  &279   &619 \\
            \multicolumn{1}{|c|}{\textbf{pcms}}  &13 644   &133 276   &23.047 &110.327  &17  &9   &9  &0  &378   &10 470 \\
            \multicolumn{1}{|c|}{\textbf{pdbs}}  &894 260  &854 720   &321.67 &1042.341 &123 &544 &18 &17 &2 845 &7 152 \\
            \multicolumn{1}{|c|}{\textbf{ppigo}} &714      &312       &6.932  &5.473    &6   &2   &5  &0  &30    &65 \\
            \hline
        \end{tabular}
        \caption{Number of nodes of search effort for each dataset. Blue for solvable and red for unsolvable SIP instances}
        \label{table:SATUNSATnodes}
    \end{table}


\subsubsection{Hardness of SIP in terms of running time}



\chapter{Empirical Study}
    \section{Filter-Verification methods}
    	\subsection{CT-Index}
        - my evaluation
        \subsection{Path-based indexing implementations}
    \section{Light Filters}
    
\chapter{Conclusion and Future work}
	\section{What did we do? What does it suggest?}
    \section{Suggestions for Future work}

%%%%%%%%%%%%%%%%
%              %
%  APPENDICES  %
%              %
%%%%%%%%%%%%%%%%
\begin{appendices}

\chapter{Implementation}

%%%% table with query answers %%%%
\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.3}% Spread rows out...
\begin{tabular}{ >{\centering\bfseries}m{1in} >{\centering\arraybackslash}m{1.3in}  } 
\toprule
  Query Number & Answers Number\\
\midrule
 \textbf{0} &  8 042\\
 \rowcolor{Gray}
 \textbf{1} & 11 957\\
 \textbf{2} & 78\\
 \rowcolor{Gray}
 \textbf{3} & 461\\
 \textbf{4} & 77\\
  \rowcolor{Gray}
 \textbf{5} & 3\\ 
 \bottomrule
\end{tabular}
\caption{The number of answers for each query for aids dataset}
\label{table:answers}
\end{table}        
%%%%

An example of running from the command line is as follows:
\begin{verbatim}
      > java MaxClique BBMC1 brock200_1.clq 14400
\end{verbatim}
This will apply $BBMC$ with $style = 1$ to the first brock200 DIMACS instance allowing 14400 seconds of cpu time.

\chapter{Generating Random Graphs}
\label{sec:randomGraph}
We generate Erd\'{o}s-R\"{e}nyi random graphs $G(n,p)$ where $n$ is the number of vertices and
each edge is included in the graph with probability $p$ independent from every other edge. It produces
a random graph in DIMACS format with vertices numbered 1 to $n$ inclusive. It can be run from the command line as follows to produce 
a clq file
\begin{verbatim}
      > java RandomGraph 100 0.9 > 100-90-00.clq
\end{verbatim}
\end{appendices}

%%%%%%%%%%%%%%%%%%%%
%   BIBLIOGRAPHY   %
%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{plain}
\bibliography{bib}

\end{document}
